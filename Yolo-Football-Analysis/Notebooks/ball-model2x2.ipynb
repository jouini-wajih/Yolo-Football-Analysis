{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9684711,"sourceType":"datasetVersion","datasetId":5920114}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install  -U ultralytics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-22T15:29:32.781313Z","iopub.execute_input":"2024-10-22T15:29:32.781803Z","iopub.status.idle":"2024-10-22T15:29:46.572860Z","shell.execute_reply.started":"2024-10-22T15:29:32.781762Z","shell.execute_reply":"2024-10-22T15:29:46.571780Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.19-py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.19-py3-none-any.whl (876 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m876.6/876.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.19 ultralytics-thop-2.0.9\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:09:11.277070Z","iopub.execute_input":"2024-10-22T15:09:11.277685Z","iopub.status.idle":"2024-10-22T15:09:17.049563Z","shell.execute_reply.started":"2024-10-22T15:09:11.277648Z","shell.execute_reply":"2024-10-22T15:09:17.048197Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-24.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import ultralytics\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:29:46.575211Z","iopub.execute_input":"2024-10-22T15:29:46.575633Z","iopub.status.idle":"2024-10-22T15:29:50.563596Z","shell.execute_reply.started":"2024-10-22T15:29:46.575588Z","shell.execute_reply":"2024-10-22T15:29:50.562679Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.19 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5933.9/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/input/ball-dataset2x2 /kaggle/working/ball_dataset2x2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:29:50.564829Z","iopub.execute_input":"2024-10-22T15:29:50.565269Z","iopub.status.idle":"2024-10-22T15:30:02.285307Z","shell.execute_reply.started":"2024-10-22T15:29:50.565232Z","shell.execute_reply":"2024-10-22T15:30:02.284207Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.3)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\n# Log in to W&B\nwandb.login(key='fa93f30a9bb3a44695b661c8acb0629b6c8f27b5')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:30:59.721033Z","iopub.execute_input":"2024-10-22T15:30:59.721912Z","iopub.status.idle":"2024-10-22T15:31:01.229427Z","shell.execute_reply.started":"2024-10-22T15:30:59.721858Z","shell.execute_reply":"2024-10-22T15:31:01.228536Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='ball_model2x2_v0')  # Change 'my_new_project' to your desired project name","metadata":{"execution":{"iopub.status.busy":"2024-10-21T15:45:01.211520Z","iopub.execute_input":"2024-10-21T15:45:01.211900Z","iopub.status.idle":"2024-10-21T15:45:04.675299Z","shell.execute_reply.started":"2024-10-21T15:45:01.211862Z","shell.execute_reply":"2024-10-21T15:45:04.674359Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112735033333997, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7afbf89732e4129912aa364ea80bbdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241021_154501-k47g7cqw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0/runs/k47g7cqw' target=\"_blank\">glowing-morning-1</a></strong> to <a href='https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0' target=\"_blank\">https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0/runs/k47g7cqw' target=\"_blank\">https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0/runs/k47g7cqw</a>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jouiniwajih2001-fst/ball_model2x2_v0/runs/k47g7cqw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x799398caa680>"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"/kaggle/working/ball_dataset2x2/data.yaml\",\"r\") as f:\n    for l in f.readlines():\n        print(l)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:06:47.654437Z","iopub.execute_input":"2024-10-22T14:06:47.655527Z","iopub.status.idle":"2024-10-22T14:06:47.661226Z","shell.execute_reply.started":"2024-10-22T14:06:47.655475Z","shell.execute_reply":"2024-10-22T14:06:47.660330Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"names:\n\n- ball\n\nnc: 1\n\ntest: /kaggle/working/ball_dataset2x2/test/images\n\ntrain: /kaggle/working/ball_dataset2x2/train/images\n\nval: /kaggle/working/ball_dataset2x2/val/images\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!yolo task=detect mode=train model=yolov10x.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.9 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123 ","metadata":{"execution":{"iopub.status.busy":"2024-10-21T15:51:29.150404Z","iopub.execute_input":"2024-10-21T15:51:29.151308Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10x.pt to 'yolov10x.pt'...\n100%|███████████████████████████████████████| 61.4M/61.4M [00:00<00:00, 208MB/s]\nUltralytics 8.3.18 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10x.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.9, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v0\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 14.0MB/s]\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1123/1135 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v0', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241021_155153-y9arh9lh\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/y9arh9lh\u001b[0m\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n100%|██████████████████████████████████████| 5.35M/5.35M [00:00<00:00, 62.1MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 90.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.29G reserved, 0.28G allocated, 14.17G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.411         109.3           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         111.4           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.552         121.6           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.684         201.6           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 8203 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 202.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 11.75G/14.74G (80%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels... 1058 images, 0 b\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/ball_dataset2x2/train/labels.cache\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels... 200 images, 0 backgr\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ball_dataset2x2/val/labels.cache\nPlotting labels to ball_models/ball_model2x2_v0/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v0\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      1/300       9.2G      5.553      16.63      1.946          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200     0.0081       0.22    0.00358    0.00115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      2/300      8.66G      6.026      5.115          2          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200    0.00485      0.305    0.00282   0.000856\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      3/300      8.73G       5.68      4.825      1.966          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.119        0.3      0.067     0.0162\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      4/300      8.71G      5.633       4.85      1.919          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.539      0.445      0.483      0.142\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      5/300      8.71G      5.473      4.546      1.907          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.653       0.44      0.541      0.183\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      6/300      8.71G      5.217      4.246      1.897          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.644      0.515      0.532      0.167\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      7/300      8.71G      5.185      4.003       1.86          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.634      0.415      0.473      0.149\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      8/300      8.66G      5.172      4.112       1.86          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.55      0.445      0.439      0.144\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      9/300      8.72G      5.135       3.69      1.854          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.562      0.564      0.547      0.161\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     10/300      8.66G      4.817      3.451      1.809          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.605      0.553      0.554      0.172\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     11/300      8.71G      4.813      3.591       1.81          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.542      0.514       0.47      0.154\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     12/300      8.72G      4.747      3.508      1.784          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.613      0.535      0.563      0.209\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     13/300      8.71G      4.963      3.593       1.82          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.662      0.515      0.616      0.246\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     14/300      8.71G      4.777      3.318      1.804          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.578      0.565      0.566      0.198\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     15/300      8.71G        4.8      3.366      1.763          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.598       0.61      0.593      0.191\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     16/300      8.71G      4.744      3.341      1.808          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.625       0.55      0.568       0.17\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     17/300      8.64G       4.61      3.373      1.781          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.646       0.52      0.589      0.237\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     18/300      8.71G      4.715      3.372      1.804          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.661      0.585      0.649      0.257\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     19/300      8.67G      4.625      3.157      1.777          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.685      0.533       0.63      0.218\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     20/300      8.71G      4.878      3.301      1.816          4        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.653      0.648      0.669      0.275\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     21/300      8.72G       4.58      2.965      1.795          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.692      0.635       0.67      0.264\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     22/300      8.72G      4.643      3.245      1.762          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.566      0.585      0.563      0.207\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     23/300      8.71G      4.549      3.095       1.76          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.652      0.605      0.652      0.277\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     24/300      8.71G      4.418      2.973      1.731          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.731        0.6      0.666      0.266\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     25/300      8.71G      4.524       3.03      1.792          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.674      0.625      0.661      0.276\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     26/300      8.65G      4.395      2.874      1.766          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.674      0.645      0.698      0.293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     27/300      8.72G      4.329      2.722      1.724          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.667      0.655      0.691      0.284\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     28/300      8.66G      4.344      2.907       1.76          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.692      0.625      0.644      0.276\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     29/300      8.72G      4.415      2.799      1.736          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.678       0.59      0.653      0.283\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     30/300      8.71G      4.347       2.75      1.757          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.691      0.626      0.646       0.25\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     31/300      8.73G      4.302      2.607      1.722          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.643      0.605      0.636      0.247\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     32/300      8.72G      4.377      2.785       1.76          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.72      0.669        0.7      0.282\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     33/300      8.71G       4.27       2.62      1.744          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.602      0.655      0.674      0.265\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     34/300      8.71G      4.351      2.605      1.754          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.653      0.583      0.633       0.23\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     35/300      8.64G      4.373      2.668      1.754          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.806      0.645      0.727      0.266\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     36/300      8.72G      4.215      2.494      1.739          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.727      0.585      0.656      0.278\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     37/300      8.65G      4.236      2.489      1.722          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.735      0.638        0.7      0.284\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     38/300      8.71G      4.305      2.458      1.746          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.803      0.625      0.719      0.289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     39/300      8.73G      4.336      2.531      1.743          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.766      0.595      0.695      0.293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     40/300      8.73G      4.243      2.527      1.714          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.788      0.669      0.755      0.324\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     41/300      8.71G      4.184      2.515      1.743          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.71      0.648      0.683       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     42/300      8.71G      4.282      2.359       1.73          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.785       0.65      0.725      0.307\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     43/300      8.72G      4.137        2.3      1.742          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.768      0.645      0.722      0.305\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     44/300      8.66G      4.175      2.373      1.729          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.715      0.676      0.742      0.316\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!yolo task=detect mode=train model=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.9 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123 resume=True ","metadata":{"execution":{"iopub.status.busy":"2024-10-21T17:24:35.568201Z","iopub.execute_input":"2024-10-21T17:24:35.568624Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.18 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.9, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v0\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v0', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241021_172444-2beunsl0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/2beunsl0\u001b[0m\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1135/1135 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 90.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.29G reserved, 0.28G allocated, 14.17G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.411          97.4           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         85.59           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.552         115.1           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.684         203.1           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 9095 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 202.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 11.75G/14.74G (80%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels.cache... 1058 image\u001b[0m\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels.cache... 200 images, 0 \u001b[0m\nPlotting labels to ball_models/ball_model2x2_v0/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\nResuming training /kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt from epoch 51 to 300 total epochs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v0\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     51/300      9.32G      4.081      3.049      1.723          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     52/300      8.71G      4.117       2.36      1.716          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.741      0.558      0.605      0.212\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     53/300      8.71G      4.155      2.289       1.72          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.739       0.62       0.63       0.26\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     54/300       8.7G        4.1      2.214      1.723          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.705      0.695      0.738      0.316\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     55/300      8.71G      4.215      2.285      1.726          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.703       0.68      0.722       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     56/300      8.71G      4.047      2.175      1.743          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.783       0.69      0.762      0.328\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     57/300      8.65G      4.269      2.194      1.731          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.762       0.69      0.744      0.317\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     58/300      8.72G       3.96      2.162      1.704          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.725        0.7       0.76      0.347\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     59/300      8.64G      4.041      2.088      1.713          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.701      0.667      0.701      0.251\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     60/300      8.72G      3.968      2.057      1.712          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.844       0.59      0.756      0.331\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     61/300      8.71G      3.913      2.003      1.703          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.726       0.61      0.671      0.295\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     62/300      8.71G      3.828      2.022       1.68          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.702      0.706      0.736      0.328\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     63/300       8.7G      4.002      2.027      1.714          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.75       0.59      0.677      0.274\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     64/300      8.71G       3.86      1.952      1.708          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.771       0.71      0.764      0.338\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     65/300      8.71G      3.952      1.986      1.681          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.778      0.615       0.71       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     66/300      8.66G      3.953      2.028      1.704          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.747      0.665      0.742        0.3\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     67/300      8.56G       3.96      2.017      1.709          8        640:  ","output_type":"stream"}]},{"cell_type":"code","source":"!yolo task=detect mode=train model=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch115.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.99 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123 resume=True amp=False","metadata":{"execution":{"iopub.status.busy":"2024-10-22T14:18:48.184316Z","iopub.execute_input":"2024-10-22T14:18:48.185267Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.19 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch115.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.99, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch115.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v0\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 11.6MB/s]\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v0', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241022_141908-igjfhdgw\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/igjfhdgw\u001b[0m\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1135/1135 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 99.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.30G reserved, 0.28G allocated, 15.30G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.407         102.6           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         81.68           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.543         138.1           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.679         257.6           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 35.12 MiB is free. Process 3463 has 15.85 GiB memory in use. Of the allocated memory 15.33 GiB is allocated by PyTorch, and 212.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 9 for CUDA:0 14.93G/15.89G (94%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels.cache... 1058 image\u001b[0m\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels.cache... 200 images, 0 \u001b[0m\nPlotting labels to ball_models/ball_model2x2_v0/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\nResuming training /kaggle/working/ball_models/ball_model2x2_v0/weights/epoch115.pt from epoch 117 to 300 total epochs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v0\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    117/300      11.7G        nan        nan        nan          9        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    118/300      11.4G        nan        nan        nan          4        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    119/300      11.3G        nan        nan        nan          6        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    120/300      11.3G        nan        nan        nan          8        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    121/300      11.3G        nan        nan        nan          8        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    122/300      11.3G        nan        nan        nan         13        640:  ","output_type":"stream"}]},{"cell_type":"code","source":"!yolo task=detect mode=train model=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.9 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123 resume=True ","metadata":{"execution":{"iopub.status.busy":"2024-10-21T18:55:09.570260Z","iopub.execute_input":"2024-10-21T18:55:09.570686Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.18 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.9, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v0\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 14.6MB/s]\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v0', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241021_185528-zborxuex\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/zborxuex\u001b[0m\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1135/1135 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 90.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.29G reserved, 0.28G allocated, 14.17G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.411          99.4           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         80.61           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.552         111.9           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.684         204.4           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 4674 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 202.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 11.75G/14.74G (80%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels.cache... 1058 image\u001b[0m\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels.cache... 200 images, 0 \u001b[0m\nPlotting labels to ball_models/ball_model2x2_v0/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\nResuming training /kaggle/working/ball_models/ball_model2x2_v0/weights/last.pt from epoch 82 to 300 total epochs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v0\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     82/300      9.32G      3.622      1.789      1.675          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.803      0.765      0.831       0.38\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     83/300      8.71G      3.528      1.618      1.665          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.79      0.754      0.813      0.358\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     84/300      8.71G      3.615      1.684      1.676          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.791       0.71      0.786      0.362\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     85/300       8.7G      3.584      1.578      1.666          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.801       0.72       0.79      0.358\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     86/300      8.71G      3.769      1.663      1.685          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.753      0.735      0.779       0.33\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     87/300      8.71G      3.499      1.564       1.69          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.76      0.785      0.819      0.374\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     88/300      8.65G      3.571      1.601      1.675          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.823       0.75       0.81      0.349\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     89/300      8.71G      3.419       1.54      1.664          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.85      0.706      0.801       0.36\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     90/300      8.64G       3.59      1.727      1.673          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.756      0.775      0.807      0.355\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     91/300      8.72G      3.651      1.689      1.674          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.806      0.745      0.805      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     92/300      8.71G      3.548      1.614      1.673          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.852       0.75      0.819      0.375\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     93/300      8.71G      3.451       1.62       1.64          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     94/300      8.71G        nan        nan        nan          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     95/300      8.71G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     96/300      8.71G        nan        nan        nan          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     97/300      8.65G        nan        nan        nan          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     98/300      8.72G      3.493      1.634      1.654          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     99/300      8.65G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    100/300      8.71G        nan        nan        nan          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    101/300      8.71G        nan        nan        nan          4        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    102/300      8.71G      3.517      1.541       1.68          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    103/300      8.71G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    104/300      8.72G       3.55      1.688      1.663          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200       0.86      0.736      0.828      0.372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    105/300      8.55G      3.541      1.733       1.64          6        640:  ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!yolo task=detect mode=train model=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch90.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.9 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123 resume=True ","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:38:05.323718Z","iopub.execute_input":"2024-10-22T15:38:05.324653Z","iopub.status.idle":"2024-10-22T16:01:51.642566Z","shell.execute_reply.started":"2024-10-22T15:38:05.324610Z","shell.execute_reply":"2024-10-22T16:01:51.641595Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.19 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch90.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.9, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/kaggle/working/ball_models/ball_model2x2_v0/weights/epoch90.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v0\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v0', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241022_153814-zc9jtrk8\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v0\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/zc9jtrk8\u001b[0m\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1135/1135 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 90.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.29G reserved, 0.28G allocated, 14.17G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.411          87.9           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         85.73           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.552           113           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.684         212.6           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 10918 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 202.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 11.75G/14.74G (80%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels.cache... 1058 image\u001b[0m\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels.cache... 200 images, 0 \u001b[0m\nPlotting labels to ball_models/ball_model2x2_v0/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\nResuming training /kaggle/working/ball_models/ball_model2x2_v0/weights/epoch90.pt from epoch 92 to 300 total epochs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v0\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     92/300      9.32G        3.5      1.684      1.667          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     93/300      8.71G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     94/300      8.71G      3.453      1.552      1.668          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     95/300       8.7G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     96/300      8.71G        nan        nan        nan          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     97/300      8.71G      3.365       1.49      1.684          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     98/300      8.65G       3.39      1.458      1.663          3        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     99/300      8.71G      3.221      1.406      1.645          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    100/300      8.64G      3.455      1.478      1.665          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    101/300      8.72G      3.459      1.494      1.665          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    102/300      8.71G      3.631       1.62      1.677          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    103/300      8.71G      3.386      1.586      1.637          0        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    104/300      8.71G       3.52      1.577      1.665          2        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    105/300      8.71G      3.386      1.589       1.66          1        640: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        200        200      0.775      0.722      0.765      0.359\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    106/300      8.55G      3.626      1.633      1.653          6        640:  ^C\n    106/300      8.55G      3.626      1.633      1.653          6        640:  \nTraceback (most recent call last):\n  File \"/opt/conda/bin/yolo\", line 8, in <module>\n    sys.exit(entrypoint())\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 824, in entrypoint\n    getattr(model, mode)(**overrides)  # default args from model\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 802, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 207, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n    self.loss, self.loss_items = self.model(batch)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 111, in forward\n    return self.loss(x, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 293, in loss\n    return self.criterion(preds, batch)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/utils/loss.py\", line 742, in __call__\n    loss_one2many = self.one2many(one2many, batch)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/utils/loss.py\", line 220, in __call__\n    imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"!yolo task=detect mode=train model=yolov10x.pt data=/kaggle/working/ball_dataset2x2/data.yaml batch=0.9 epochs=300 imgsz=640 visualize=True verbose=True plots=True save=True save_period=5 project=\"ball_models\" name=\"ball_model2x2_v0\" seed=123  ","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:33:51.220963Z","iopub.execute_input":"2024-10-22T15:33:51.221821Z","iopub.status.idle":"2024-10-22T15:34:44.984746Z","shell.execute_reply.started":"2024-10-22T15:33:51.221777Z","shell.execute_reply":"2024-10-22T15:34:44.983760Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Ultralytics 8.3.19 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10x.pt, data=/kaggle/working/ball_dataset2x2/data.yaml, epochs=300, time=None, patience=100, batch=0.9, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=ball_models, name=ball_model2x2_v02, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=123, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=ball_models/ball_model2x2_v02\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1    213120  ultralytics.nn.modules.block.SCDown          [320, 640, 3, 2]              \n  6                  -1  6   4604160  ultralytics.nn.modules.block.C2fCIB          [640, 640, 6, True]           \n  7                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n  8                  -1  3   2712960  ultralytics.nn.modules.block.C2fCIB          [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1   1545920  ultralytics.nn.modules.block.PSA             [640, 640]                    \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 17                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  3   2917760  ultralytics.nn.modules.block.C2fCIB          [960, 640, 3, True]           \n 20                  -1  1    417920  ultralytics.nn.modules.block.SCDown          [640, 640, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  3   3122560  ultralytics.nn.modules.block.C2fCIB          [1280, 640, 3, True]          \n 23        [16, 19, 22]  1   4386966  ultralytics.nn.modules.head.v10Detect        [1, [320, 640, 640]]          \nYOLOv10x summary: 688 layers, 31,656,806 parameters, 31,656,790 gradients, 171.0 GFLOPs\n\nTransferred 1123/1135 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ball_models/ball_model2x2_v02', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjouiniwajih2001\u001b[0m (\u001b[33mjouiniwajih2001-fst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241022_153401-ucg88f0h\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mball_model2x2_v02\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jouiniwajih2001-fst/ball_models/runs/ucg88f0h\u001b[0m\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 90.0% CUDA memory utilization.\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.29G reserved, 0.28G allocated, 14.17G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n    31656806         171         1.411         88.41           nan        (1, 3, 640, 640)                    list\n    31656806         342         3.458         87.32           nan        (2, 3, 640, 640)                    list\n    31656806         684         6.552         112.2           nan        (4, 3, 640, 640)                    list\n    31656806        1368        12.684         209.6           nan        (8, 3, 640, 640)                    list\nCUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 8672 has 14.72 GiB memory in use. Of the allocated memory 14.37 GiB is allocated by PyTorch, and 202.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 11.75G/14.74G (80%) ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ball_dataset2x2/train/labels.cache... 1058 image\u001b[0m\n/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ball_dataset2x2/val/labels.cache... 200 images, 0 \u001b[0m\nPlotting labels to ball_models/ball_model2x2_v02/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 185 weight(decay=0.0), 198 weight(decay=0.0004921875), 197 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mball_models/ball_model2x2_v02\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      1/300      9.03G      6.029      85.35        2.1         10        640:  ^C\n      1/300      9.03G      6.029      85.35        2.1         10        640:  \nTraceback (most recent call last):\n  File \"/opt/conda/bin/yolo\", line 8, in <module>\n    sys.exit(entrypoint())\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 824, in entrypoint\n    getattr(model, mode)(**overrides)  # default args from model\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 802, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 207, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 385, in _do_train\n    self.loss, self.loss_items = self.model(batch)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 111, in forward\n    return self.loss(x, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 293, in loss\n    return self.criterion(preds, batch)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/utils/loss.py\", line 742, in __call__\n    loss_one2many = self.one2many(one2many, batch)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/utils/loss.py\", line 220, in __call__\n    imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\nKeyboardInterrupt\n","output_type":"stream"}]}]}